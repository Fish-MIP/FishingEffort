---
title: "Catch_data"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aim 

The aim of this file is to aggregate Reg's historical catch data as per Yannick's effort data 

ORIGIN: data sent from Reg on 20/05/22 - RE: question about mapping catch and effort

WARNING on units and weights: Should we weight catch (and effort, script 02) by grip cell area when summarising at LME, EEZ level? it seems not - see Reg's email conversation. Also the non-weighted value match Yannick's and Reg's global totals. 

FORMAT:  
1. from Reg: Data by cell (with lat and long) by year by country fishing (represented by a code CNumber) by FGroup (represented by a code). The numbers are in tonnes for reported, IUU and Discards. Typically you would ignore discards as they can be any species (not the one in the record usually). So I would combine reported and IUU estimated (see email conversation on discards).
2. Catch is in tonnes (by grid cell), can /area grid cell to get catch rates. Reg NOTES: "PPS if you decide to map using the cell data then you should NOT use the tonnes but rather the catch rate (tonnes per sq km of ocean) as the cells vary in size and tonnes would be misleading ..."

## Add LME and EEZ to historical cacth data from Reg 

```{r new data}

rm(list=ls())

library(tidyverse)
library(data.table)
library(dtplyr)
library(tictoc)

# historical/ industrial 
hist<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/HistoricalIndCami.csv")
head(hist)
nrow(hist)
hist<-lazy_dt(hist)

# non historical / non industrial 
recent_art<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/NonHistoricalNIndCami.csv")
head(recent_art)
nrow(recent_art)
recent_art<-lazy_dt(recent_art)

# non historical / industrial
tic()
recent_ind<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/NonHistoricalIndCami_toCombine/NonHistoricalIndCami.csv")
head(recent_ind) 
nrow(recent_ind)
toc()
recent_ind<-lazy_dt(recent_ind)

# all data merged! 
catch<-hist %>% 
  full_join(recent_art) %>% 
  full_join(recent_ind)

# head(as.data.table(catch))
# nrow(as.data.table(catch)) # 116450350
# nrow(hist) + nrow(recent_ind) + nrow(recent_art) # 116450350
# sort(unique(as.data.table(catch)$Year)) # 1869 - 2017

# use same approach as in 02_merge_effort_spetial_data.Rmd to add LME, EEZ, FAO regions and aggregate data by these groups

```

# Explore files and join the main data

```{r}

### paste code from script 02

library(dplyr)
library(vroom)
library(parallel)
library(geoR)
library(raster)
library(here)
library(RColorBrewer)

select <- dplyr::select
rename <- dplyr::rename

yannick_dir <- "/rd/gem/private/users/yannickr"

(EEZ <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv"))) 

## CN how many before we filter? 
EEZ_tot<-EEZ %>% 
  filter(FAOname != "High Seas") %>% 
  select(FAOname, CNumber) %>% 
  unique()

nrow(EEZ_tot) # 193
 
#EEZ data is duplicated in places because of disputed claims to cells - just going to take the first country listed
(EEZ_disputes <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv")) %>% filter(DISPUTED==TRUE))

(take_first <- EEZ_disputes[!duplicated(EEZ_disputes[c("Lon", "Lat")]),])

head(EEZ) # CN - might need to change aggregation levels - use the FAOname as the  Admin_Country aggregates EEZ that are under the same administrative country. 
unique(EEZ[,c("CNumber", "FAOname", "A_Code", "Admin_Country")])
# View(unique(EEZ[,c("CNumber", "FAOname")])) # unique CNubmer and FAOName
# View(unique(EEZ[,c("A_Code", "FAOname")])) # repeated A_Code for some FAOname (I guess under the same Admin_country)

(EEZ_adj <- bind_rows(EEZ %>% 
            filter(DISPUTED == FALSE),
          take_first) %>% 
  # select(Lat, Lon, A_Code, Admin_Country) %>% # CN changed - we need the EEZ and not the administrative country
  select(Lat, Lon, CNumber, FAOname) %>%
  # rename(eez_country_code = A_Code,
        # eez_country_name = Admin_Country) %>% # CN same as above
  rename(eez_country_code = CNumber,
         eez_country_name = FAOname) %>%
   distinct())

united_coords <- EEZ_adj %>% unite("coords", c("Lon", "Lat"), sep = " ")

EEZ_adj <- EEZ_adj[-which(duplicated(united_coords[,"coords"])==TRUE),] %>% as.data.table() # remove duplicated EEZ records
EEZ_adj <- lazy_dt(EEZ_adj)

# check EEZ data - EEZs look ok

# EEZ_xyz <- EEZ_adj %>% as_tibble() %>%  rename(x=Lon, y= Lat, z=eez_country_code) %>%  select(x,y,z)  # CN adjust as per above 
EEZ_xyz <- EEZ_adj %>% as_tibble() %>%  rename(x=Lon, y= Lat, z=eez_country_code) %>%  select(x,y,z) 
EEZ_raster <- raster::rasterFromXYZ(EEZ_xyz)
plot(EEZ_raster) # CN to 800 because this is eez_country_code
# unique(EEZ_raster$z)

EEZ_adj<-EEZ_adj %>% select(-eez_country_code) # CN no need for this anymore - avoid confusion 
nrow(as.data.table(EEZ_adj))
EEZ_adj<-unique(EEZ_adj)
nrow(as.data.table(EEZ_adj))

# ggplot(data = EEZ_xyz)+
#   geom_tile(aes(x=x, y=y, fill=z)) + 
#   scale_fill_gradientn(colours = RColorBrewer::brewer.pal(n = 9, name = "Spectral"))
# 
# ggsave(filename = here("Explore/cottrell-explore/eez_wo_duplicates_CN.jpg"), dpi=300, device = "jpg", width = 9, height = 5)

#LME data
(LMEs <- fread(file.path(yannick_dir, "LMESeq.csv")))
LMEs <- lazy_dt(LMEs)

LME_xyz <- LMEs %>% as_tibble() %>%  rename(x=Lon, y= Lat, z=LME) %>%  select(x,y,z) 
LME_raster <- raster::rasterFromXYZ(LME_xyz)
plot(LME_raster) # CN NOTE - land is 0 here.  

#FAO regions data
(FAO_regions <- readRDS(file.path(yannick_dir, "Cells_LatLon_FAO_regions.rds")) %>% 
    rename(Lon=x, Lat = y) %>% mutate(fao_area= as.double(fao_area)) %>% as.data.table())

FAO_regions <- lazy_dt(FAO_regions)

FAO_xyz <- FAO_regions %>% as_tibble() %>%  rename(x=Lon, y= Lat, z=fao_area) %>%  select(x,y,z) 
FAO_raster <- raster::rasterFromXYZ(FAO_xyz)
plot(FAO_raster) # CN NOTE - land is a mix of NAs and the actual FAO region. it makes sense by looking at the map from website though land there is overplayed and here not important as no data will be there. 

# for eez: Looking at the CNumber - this appears the be the iso3n code for the country. This is often the name the same as the admin country but is different when the land masses are territories of other countries

#The data have different rows. Want to make sure they line up
nrow(EEZ_adj) #179904
nrow(as_tibble(LMEs)) #259200
nrow(FAO_regions) #229369

#Some LME data are around that have no FAO or EEZ data
(all_spatial_layers <- 
  full_join(x = full_join(x = LMEs %>% select(-Seq), y = FAO_regions, by = c("Lon", "Lat")), 
            y = EEZ_adj %>% select(Lon, Lat, eez_country_name), by = c("Lon", "Lat")) %>% as_tibble()
)

missing_fao_eez <- 
  all_spatial_layers %>% 
  filter(is.na(fao_area)) %>% #29831 where FAO areas are NA but LME are not
  filter(is.na(eez_country_name)) #29830 where EEZ are NA but LME are not - this does not change depending on order. So there is one cell where the is LME data and EEZ data but not FAO area data

# Camilla's CHECKS - IMPORTANT 
# the above one grid cell needs to be fixed otherwise it is carried out in final effort dataset and giving an additional FAO region called 'NA', where LME = 0 and EEZ = GuineaBissau
# by looking at map, this is FAO 34
all_spatial_layers %>% 
  filter(is.na(fao_area) & !is.na(eez_country_name) & !is.na(LME))

a<-data.frame(Lon =-14.75, Lat=12.25, fao_area=34)
FAO_regions<-FAO_regions %>% full_join(a)
FAO_regions %>% filter(Lon == -14.75, Lat == 12.25)

```

# Run function to aggregate data 

```{r}

# unique(sort(as.data.table(catch)$Lat))
# unique(sort(as.data.table(catch)$Lon))
# 
# unique(sort(as.data.table(LMEs)$Lat))
# unique(sort(as.data.table(LMEs)$Lon))
# 
# unique(sort(as.data.table(EEZ_adj)$Lat))
# unique(sort(as.data.table(EEZ_adj)$Lon))

# head(catch)

tic()
catch2 <- catch %>%
  select(-Seq) %>% 
  left_join(LMEs, by=c("Lat", "Lon")) %>%
  left_join(EEZ_adj, by=c("Lat", "Lon")) %>%
  left_join(FAO_regions, by=c("Lat", "Lon")) %>%
  group_by(Year,CNumber,FGroup,fao_area, LME, eez_country_name,Sector) %>%
  summarise(Reported = sum(Reported, na.rm = TRUE),
            IUU = sum(IUU, na.rm = TRUE),
            Discards = sum(Discards, na.rm = TRUE)) %>% 
  ungroup() %>% 
  as.data.table() 
toc()# 383.162 # 6 min

```

## format catch as effort file  

```{r catch}

# ORIGIN: created through script 02 from original Yannicks country files in Gem48 and re-arranged and trimmed in script 05.    
# effort<-fread("/rd/gem/private/users/yannickr/effort_histsoc_1950_2017_EEZ.csv") # use EEZ version where EEZ is not the administrative country
effort<-fread("/rd/gem/private/users/yannickr/effort_histsoc_1950_2017_EEZ_addFAO.csv") # use EEZ version where EEZ is not the administrative country and where FAO regions are added 
# head(effort)
effort<-effort[,-1]

# do the LME and EEZ match? ----

# EEZ - OK
sort(unique(catch2$eez_country_name), na.last = TRUE)
sort(unique(effort$eez_country_name), na.last = TRUE)

# LME - OK
sort(unique(catch2$LME),na.last = TRUE)
sort(unique(effort$LME), na.last = TRUE)

# fishing country 
saup<-read_csv("/rd/gem/private/users/yannickr/SAUPcode_to_Country.csv")

# # is CNumber == SAUP? it looks like it. yes also from Reg's email where CNumber = fishing country 
# sort(unique(catch$CNumber)) 
# sort(unique(saup$SAUP_Country_Nbr))
# unique(filter(catch, CNumber == 124)$eez_country_name)
# filter(saup, SAUP_Country_Nbr == 124)

saup<-saup %>% 
  dplyr::rename(SAUP = SAUP_Country_Nbr,
                FCountryName = Country) %>% 
  select(-Region)

catch2<-catch2 %>% 
  dplyr::rename(SAUP = CNumber) %>% 
  left_join(saup, by ="SAUP")

# FGroup
taxon<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/CodesRevisedJune2022_FGroup.csv")

# clean
taxon<-taxon %>% 
  mutate(Description = gsub(" ", "", Description, fixed = TRUE),
         Description = gsub(",", "", Description, fixed = TRUE)) %>% # remove white spaces 
  select(FunctionalGrp, Description) %>% 
  unique()

# any missing one in effort/ catch? No - all OK
setdiff(unique(taxon$Description), unique(effort$FGroup))
setdiff(unique(effort$FGroup),unique(taxon$Description)) # Unknown_EEZ which will be removed in 07

sort(unique(taxon$Description), na.last = TRUE)
sort(unique(effort$FGroup), na.last = TRUE) # Unknown_EEZ which will be removed in 07

# merge 
catch2<-catch2 %>% 
  left_join(taxon %>% dplyr::rename(FGroup = FunctionalGrp)) %>% 
  select(-FGroup) %>% 
  dplyr::rename(FGroup = Description)

# sector
catch2<-catch2 %>% 
  mutate(Sector = ifelse(Sector == 2, "artisanal", "industrial"))

```

# check catch data given Reg summaries and plots
checked also with Watson and Tidd 2018 and looks OK https://www.sciencedirect.com/science/article/pii/S0308597X18300605 

```{r}

annual<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/CheckCatchTotalsCN.csv")

head(annual)
unique(annual$Sector)
annual<-annual %>% 
  mutate(Sector = ifelse(Sector == "artisanal", "artisanal", "industrial")) %>% 
  select(-"...6") %>% 
  mutate(type = "summaries")

trial<-catch2 %>% 
  group_by(Year, Sector) %>% 
  summarise(Reported = sum(Reported , na.rm = TRUE),
            IUU = sum(IUU , na.rm = TRUE),
            Discards = sum(Discards , na.rm = TRUE)) %>% 
  mutate(type = "dataset")

trial2<-trial %>% 
  full_join(annual) %>% 
  as.data.frame(trial2)

trial2<-trial2 %>% 
  gather("key", "catch", -Year, -type, -Sector)

plot<-ggplot(trial2, aes(x = Year, y = catch, group = key, color = key)) + # color = Sector, group = Sector 
  geom_point()+
  theme_bw()+
  facet_grid(type~Sector)

# # version where we consider EEZ name and not administrative country and where we add FAO regions to the merging (previously there in code but committed given work on effort)
# pdf("Output/catch_compare_EEZ_addFAO.pdf", width = 10, height=7)
# plot
# dev.off()

# check nesting:  
# sum fao = sum LME = sum EEZ 
# OK but not sure this check is meaningful
check<-catch2 %>% 
  mutate(sum = Reported + IUU + Discards)

lme_check<-check %>% group_by(LME) %>% summarise(a = sum(sum)) %>% ungroup() 
lme_check %>% summarise(sum(a)) # 6940447558.

eez_check<-check %>% group_by(eez_country_name) %>% summarise(a = sum(sum)) %>% ungroup() 
eez_check %>% summarise(sum(a)) # 6940447558.

fao_check<-check %>% group_by(fao_area) %>% summarise(a = sum(sum)) %>% ungroup() 
fao_check %>% summarise(sum(a)) # 6940447558.

```

# save final data 

```{r}

final_catch <- catch2

sort(unique(as.data.frame(final_catch)$Year), na.last = TRUE)
# fwrite(x = as.data.frame(final_catch), file.path(yannick_dir, "catch_histsoc_1869_2017.csv"))
# fwrite(x = as.data.frame(final_catch), file.path(yannick_dir, "catch_histsoc_1869_2017_EEZ.csv"))
fwrite(x = as.data.frame(final_catch), file.path(yannick_dir, "catch_histsoc_1869_2017_EEZ_addFAO.csv"))

```

# explore the Unknown_EEZ FGroup in effort

```{r }

# some FGroup == "Unknown_EEZ", what does this mean? 

a<-filter(effort, FGroup == "Unknown_EEZ")
unique(a$Sector) 
unique(a$SAUP)
unique(a$NomActive)
a<-filter(effort, FGroup == "Unknown_EEZ", SAUP == 892)
unique(a$NomActive)
a<-filter(a, NomActive == 28.926300)
a

# is this group on the original files too?  
this_source_path <- file.path("/rd/gem/private/users/yannickr/effort_mapped_bycountry", "mapped_1992_UP_892.csv")
these_data <- read_csv(this_source_path)

filter(these_data, NomActive ==0) 
b<-filter(these_data, FGroup == "Unknown_EEZ", NomActive !=0)
b 
sum(b$NomActive) 
sum(filter(effort, FGroup == "Unknown_EEZ", SAUP == 892, Year ==1992, NomActive !=0)$NomActive) # OK this is matching... 

```

