---
---
#Install dependencies
```{r}
install.packages(C("purrr", "fanzi", "utf8", "R6", "tibble", "pkgconfig", "dplyr", "dtplyr", "data.table", "geoR"))

```

Libraries
```{r}

library(dtplyr)
library(dplyr)
library(data.table)
library(here)
library(vroom)
library(parallel)
library(tictoc)
library(geoR)

select <- dplyr::select

yannick_dir <- "/rd/gem/private/users/yannickr"

original_effort_dir <- "/rd/gem/private/users/yannickr/effort_mapped_bycountry"

aggregated_files_dir <- "/rd/gem/private/users/yannickr/effort_mapped_by_country_aggregated/"

```

Explore files and join the main data
```{r}

(EEZ <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv"))) 
 
#EEZ data is duplicated in places because of disputed claims to cells - just going to take the first country listed
(EEZ_disputes <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv")) %>% filter(DISPUTED==TRUE))

(take_first <- EEZ_disputes[!duplicated(EEZ_disputes[c("Lon", "Lat")]),])
     
(EEZ_adj <- bind_rows(EEZ %>% 
            filter(DISPUTED == FALSE),
          take_first) %>% 
  select(Lat, Lon, A_Code, Admin_Country) %>% 
   rename(eez_country_code = A_Code, 
          eez_country_name = Admin_Country) %>% 
   distinct())

united_coords <- EEZ_adj %>% unite("coords", c("Lon", "Lat"), sep = " ")

EEZ_adj <- EEZ_adj[-which(duplicated(united_coords[,"coords"])==TRUE),] %>% as.data.table() # remove duplicated EEZ records
EEZ_adj <- lazy_dt(EEZ_adj)


#LME data
(LMEs <- fread(file.path(yannick_dir, "LMESeq.csv")))
LMEs <- lazy_dt(LMEs)


#FAO regions data
(FAO_regions <- readRDS(file.path(yannick_dir, "Cells_LatLon_FAO_regions.rds")) %>% 
    rename(Lon=x, Lat = y) %>% mutate(fao_area= as.double(fao_area)) %>% as.data.table())

FAO_regions <- lazy_dt(FAO_regions)


# Looking at the CNumber - this appears the be the iso3n code for the country. This is often the name the same as the admin country but is different when the land masses are territories of other countries


#The data have different rows. Want to make sure they line up
nrow(EEZ) #191480
nrow(EEZ_adj) #182995
nrow(as_tibble(LMEs)) #259200
nrow(FAO_regions) #229369


#there are some cells in LME  that do not have EEZ data
LME_EEZ <- full_join(LMEs, EEZ_adj) #this 262291 - an extra (262291-259200 = 3091) rows
missing_EEZ <- LME_EEZ %>% filter(is.na(eez_country_name))%>% select(Lon, Lat, LME)


LME_EEZ %>% filter(Lon %in% missing_EEZ$Lon & Lat %in% missing_EEZ$Lat) # the presence of cells in missing data seems to vastly outnumber

#doesn't do it with these two though - perhaps the eez grid is dodgy? Try the new EEZ xy file. That worked.
LME_FAO_regions <- full_join(LMEs, FAO_regions)
LME_FAO_regions_EEZ <- full_join(LME_FAO_regions, EEZ)


#there are still cells where there is no data for eezs when there is for FAO and LME, and none for FAO when there is for LME and EEZ.
#filter both and plot them to see the error.....looks like a rasterize issue - very few number of cells missing, not too worried about that. Can edit the effort files post hoc where these data are missing for effort data (likely to be low numbers (hundreds rather than thousands of cells).

(EEZ_no_data <- LME_FAO_regions_EEZ %>% 
    filter(!(is.na(fao_area)) & is.na(eez_country)))

plot(rasterFromXYZ(EEZ_no_data %>% select(Lon, Lat, LME)))
plot(rasterFromXYZ(EEZ_no_data %>% select(Lon, Lat, fao_area)))

(FAO_no_data <- LME_FAO_regions_EEZ %>% filter((is.na(fao_area)) & !is.na(eez_country)))

plot(rasterFromXYZ(FAO_no_data %>% select(Lon, Lat, LME)))
plot(rasterFromXYZ(FAO_no_data %>% select(Lon, Lat, iso3n)))

#so there are no replicated grid cells which is positive
LME_EEZ_FAO %>% select(Lon, Lat) %>% distinct()

```

Make a function that will speedily import and merge the data files

```{r}

join_effort_data <- function(this_file_name){
  
  this_source_path <- file.path("/rd/gem/private/users/yannickr/effort_mapped_bycountry", this_file_name)
  
  this_destination_path <- paste0("/rd/gem/private/users/yannickr/effort_mapped_by_country_aggregated/", "aggregated_", this_file_name)
  
  if(file.exists(this_destination_path)){
    
    Year <- as.numeric(str_extract(this_file_name, pattern =  "([[:digit:]])+"))
    
    these_data <- fread(this_source_path)
    these_data <- lazy_dt(these_data)
    
    #data.table approach
    #tells data.table how to join
    # 
    # setkey(these_data, Lon, Lat)
    # setkey(LMEs, Lon, Lat)
    # setkey(EEZ_adj, Lon, Lat)
    # setkey(FAO_regions, Lon, Lat)
    # 
    # #make the joins of LMEs, FAO areas, and EEZs
    # merge_1 <- LMEs[these_data, on = c("Lon", "Lat")]
    # merge_2 <- FAO_regions[merge_1, on = c("Lon", "Lat")]
    # merge_3 <- EEZ_adj[merge_2, on = c("Lon", "Lat")] #merge 3 has retained the same number of rows
    # #group by all variables and sum the different effort forms, adding year at the end
    # 
    # this_aggregated_data <- 
    #   cbind(
    #     nom_active_gr <- merge_3[, .(NomActive= sum(NomActive, na.rm = TRUE)),
    #                              by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"NomActive"],
    #     eff_active_gr <-  merge_3[, .(EffActive= sum(EffActive, na.rm = TRUE)), 
    #                               by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"EffActive"],
    #     nv_gr <- merge_3[, .(NV= sum(NV, na.rm = TRUE)),
    #                      by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"NV"],
    #     p_gr <- merge_3[, .(P= sum(P, na.rm = TRUE)), 
    #                     by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"P"],
    #     gt_group <- merge_3[, .(GT= sum(GT, na.rm = TRUE)), 
    #                         by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"GT"]
    #   )[, `:=`(Year = Year)]
    
    #dtplyr approach
    these_aggregated_data <-
      these_data %>%
      left_join(LMEs, by=c("Lat", "Lon")) %>%
      left_join(EEZ_adj, by=c("Lat", "Lon")) %>%
      left_join(FAO_regions, by=c("Lat", "Lon")) %>%
      group_by(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector) %>%
      summarise(NomActive = sum(NomActive, na.rm = TRUE),
                EffActive = sum(EffActive, na.rm = TRUE),
                NV= sum(NV, na.rm = TRUE),
                P= sum(P, na.rm = TRUE),
                GT= sum(GT, na.rm = TRUE)) %>%
      mutate(Year = Year) %>% as.data.table()
    
    fwrite(x = these_aggregated_data, file = file.path(this_destination_path))
  }
  
}


```

Run the code on all 30,000 files and write them to folder
```{r}
#compressed_effort_files <- list.files(file.path(compressed_effort_dir), full.names = TRUE)
original_effort_files <- list.files(file.path(original_effort_dir), pattern = ".csv")

chunk_size <- 500 #chunk size for processing
effort_list_split <- split(original_effort_files, ceiling(seq_along(original_effort_files)/chunk_size))
length(effort_list_split) #60 chunks

tic()
for(i in 1:length(effort_list_split)){
  
  file_chunk <- effort_list_split[[i]]
  
  message("Processing chunk #", i, " of ", length(effort_list_split))
  
  mclapply(X = file_chunk, FUN = join_effort_data, mc.cores = 40)
  
}
toc()
4679.399/3600 #1.3 hours to run
```


Check the files

```{r}
#check the files
newly_written_files <- list.files(file.path(yannick_dir, "effort_mapped_by_country_aggregated"), full.names = TRUE)

#pick one randomly 
map(newly_written_files[[8]], fread)
```

Combine all listed files to one file
```{r}

combined_aggregated_effort <- rbindlist(mclapply(X = newly_written_files, FUN = fread, mc.cores = 40))

fwrite(x = combined_aggregated_effort, file.path(yannick_dir, "all_effort_aggregated.csv"))

```

