---
---

Libraries
```{r}

library(tidyverse)
library(data.table)
library(here)
library(vroom)
library(parallel)

select <- dplyr::select

yannick_dir <- "/rd/gem/private/users/yannickr"


```

Explore files and join the main data
```{r}

(EEZ <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv"))) 
 
#EEZ data is duplicated in places because of disputed claims to cells - just going to take the first country listed
(EEZ_disputes <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv")) %>% filter(DISPUTED==TRUE))

(take_first <- EEZ_disputes[!duplicated(EEZ_disputes[c("Lon", "Lat")]),])
     
(EEZ_adj <- bind_rows(EEZ %>% 
            filter(DISPUTED == FALSE),
          take_first) %>% 
  select(Lat, Lon, A_Code, Admin_Country) %>% 
   rename(eez_country_code = A_Code, 
          eez_country_name = Admin_Country) %>% 
   distinct() %>% 
    as.data.table())

(LMEs <- fread(file.path(yannick_dir, "LMESeq.csv"))[,c("Lon", "Lat", "LME")])

(FAO_regions <- readRDS(file.path(yannick_dir, "Cells_LatLon_FAO_regions.rds")) %>% 
    rename(Lon=x, Lat = y) %>% as.data.table()) 


# Looking at the CNumber - this appears the be the iso3n code for the country. This is often the name the same as the admin country but is different when the land masses are territories of other countries


#The data have different rows. Want to make sure they line up
nrow(EEZ) #191480
nrow(EEZ_new) #167373
nrow(LMEs) #259200
nrow(FAO_regions) #173097


#there are some cells in LME  that do not have EEZ data
LME_EEZ <- full_join(LMEs, EEZ) #this 270776 - an extra 11 thousand rows
missing_EEZ <- LME_EEZ %>% filter(is.na(Admin_Country))%>% select(Lon, Lat, LME)
plot(rasterFromXYZ(missing_EEZ)) #looks like they could be on the land??
LME_EEZ %>% filter(Lon %in% missing_EEZ$Lon & Lat %in% missing_EEZ$Lat) # the presence of cells in missing data seems to vastly outnumber

#doesn't do it with these two though - perhaps the eez grid is dodgy? Try the new EEZ xy file. That worked.
LME_FAO_regions <- full_join(LMEs, FAO_regions)
LME_FAO_regions_EEZ <- full_join(LME_FAO_regions, EEZ)


#there are still cells where there is no data for eezs when there is for FAO and LME, and none for FAO when there is for LME and EEZ.
#filter both and plot them to see the error.....looks like a rasterize issue - very few number of cells missing, not too worried about that. Can edit the effort files post hoc where these data are missing for effort data (likely to be low numbers (hundreds rather than thousands of cells).

(EEZ_no_data <- LME_FAO_regions_EEZ %>% 
    filter(!(is.na(fao_area)) & is.na(eez_country)))

plot(rasterFromXYZ(EEZ_no_data %>% select(Lon, Lat, LME)))
plot(rasterFromXYZ(EEZ_no_data %>% select(Lon, Lat, fao_area)))

(FAO_no_data <- LME_FAO_regions_EEZ %>% filter((is.na(fao_area)) & !is.na(eez_country)))

plot(rasterFromXYZ(FAO_no_data %>% select(Lon, Lat, LME)))
plot(rasterFromXYZ(FAO_no_data %>% select(Lon, Lat, iso3n)))

#so there are no replicated grid cells which is positive
LME_EEZ_FAO %>% select(Lon, Lat) %>% distinct()

```

Make a function that will speedily import and merge the data files

```{r}


join_effort_data <- function(this_file_name){
  
  this_source_path <- paste0(original_effort_dir, this_file_name)
  
  this_destination_path <- paste0(aggregated_files_dir, "aggregated_", this_file_name)
  
  if(file.exists(this_destination_path)){
    
    Year <- as.numeric(str_extract(this_file_name, pattern =  "([[:digit:]])+"))
    
    these_data <- fread(file.path(this_source_path))
    
    #tells data.table how to join
    setkey(these_data, Lon, Lat)
    setkey(LMEs, Lon, Lat)
    setkey(EEZ_adj, Lon, Lat)
    setkey(FAO_regions, Lon, Lat)
    
    #make the joins of LMEs, FAO areas, and EEZs
    merge_1 <- LMEs[these_data, on = c("Lon", "Lat")]
    merge_2 <- FAO_regions[merge_1, on = c("Lon", "Lat")]
    merge_3 <- EEZ_adj[merge_2, on = c("Lon", "Lat")] #merge 3 has retained the same number of rows
    
    #group by all variables and sum the different effort forms, adding year at the end
    this_aggregated_data <- 
      cbind(
    nom_active_gr <- merge_3[, .(NomActive= sum(NomActive, na.rm = TRUE)), 
                             by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )],
   eff_active_gr <-  merge_3[, .(EffActive= sum(EffActive, na.rm = TRUE)), 
                             by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"EffActive"],
   nv_gr <- merge_3[, .(NV= sum(NV, na.rm = TRUE)), 
                    by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"NV"],
   p_gr <- merge_3[, .(P= sum(P, na.rm = TRUE)), 
                   by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"P"],
   gt_group <- merge_3[, .(GT= sum(GT, na.rm = TRUE)), 
                       by = list(eez_country_name, fao_area, LME, SAUP, Gear, FGroup, Sector )][,"GT"]
    )[, `:=`(Year = Year)]
    
fwrite(x = this_aggregated_data, file = file.path(this_destination_path))
    
    
 }
  
}



```

Run the code on all 30,00 files and write them to folder
```{r}

#compressed_effort_files <- list.files(file.path(compressed_effort_dir), full.names = TRUE)
original_effort_files <- list.files(file.path(original_effort_dir), pattern = ".csv")

chunk_size <- 500 #chunk size for processing
effort_list_split <- split(original_effort_files, ceiling(seq_along(original_effort_files)/chunk_size))
length(effort_list_split) #60 chunks


for(i in 1:length(effort_list_split)){
  
  file_chunk <- effort_list_split[[i]]
  
  message("Processing chunk #", i, " of ", length(effort_list_split))
  
  mclapply(X = file_chunk, FUN = join_effort_data, mc.cores = 40)
  
}


#check the files

newly_written_files <- list.files(file.path(yannick_dir, "effort_mapped_by_country_aggregated"), full.names = TRUE)

#pick one randomly 
map(newly_written_files[[8]], fread)



```

Combine all listed files to one file
```{r}

combined_aggregated_effort <- rbindlist(mclapply(X = newly_written_files, FUN = fread, mc.cores = 40))

fwrite(x = combined_aggregated_effort, file.path(yannick_dir, "all_effort_aggregated.csv"))

```

