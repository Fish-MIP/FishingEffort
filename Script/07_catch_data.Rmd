---
title: "Catch_data"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The aim of this file is to aggregate Reg's historical catch data as per Yannick's effort data 

WARNING on units
1. Catch is in tonnes (by LME and EEZ etc), can /AreaSqKm2 to get catch rates. Though the number in each grid cell when doing the aggregation was differnt, was this considered somehow? 
2. CatchHist is in tonnes (by grid cell), can /area grid cell to get catch rates. Reg NOTES: PPS if you decide to map using the cell data then you should NOT use the tonnes but rather the catch rate (tonnes per sq km of ocean) as the cells vary in size and tonnes would be misleading ...
3. Effort is in dayKW - should we treat this as the catches and considered Area of either grid cell or LME/EEZ to get a consistent rate? Possibly not as there is no area component in this unit of effort (Ryan)? Cami - not understanding much how this works in terms of units and weights ...   

# Add LME and EEZ to historical cacth data from Reg

*WARNING* - updated catch data in /rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData
taxonomic codes updated too and now on Desktop (CodesRevisedJune2022) - see email from Reg 5/06/22 for more info on file and codes - THEN UPLOAD AND SUMMARISE HERE 
CheckCatchTotals.xls important for checking data - do same as above 

```{r new data}

rm(list=ls())

library(tidyverse)
library(data.table)
library(dtplyr)
library(tictoc)

# ORIGIN: data sent from Reg on 20/05/22 - RE: question about mapping catch and effort
# NOTE from REG: This has the data by cell (with lat and long) by year by country fishing (represented by a code CNumber) by FGroup (represented by a code). The numbers are in tonnes for reported, IUU and Discards. Typically you would ignore discards as they can be any species (not the one in the record usually). So I would combine reported and IUU estimated.

# catchHist<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/HistoricalCami2.csv")


### UPDATE data origin .... 

# historical/ industrial 
hist<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/HistoricalIndCami.csv")
head(hist)
nrow(hist)
hist<-lazy_dt(hist)

# non historical / non industrial 
recent_art<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/NonHistoricalNIndCami.csv")
head(recent_art)
nrow(recent_art)
recent_art<-lazy_dt(recent_art)

# non historical / industrial
tic()
recent_ind<-fread("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/NonHistoricalIndCami_toCombine/NonHistoricalIndCami.csv")
head(recent_ind) 
nrow(recent_ind)
toc()
recent_ind<-lazy_dt(recent_ind)

# all data merged! 
catch<-hist %>% 
  full_join(recent_art) %>% 
  full_join(recent_ind)

# head(as.data.table(catch))
# nrow(as.data.table(catch)) # 116450350
# nrow(hist) + nrow(recent_ind) + nrow(recent_art) # 116450350
# sort(unique(as.data.table(catch)$Year)) # 1869 - 2017

# use same approach as in 02_merge_effort_spetial_data.Rmd to add LME, EEZ, FAO regions and aggregate data by these groups

### paste code from script 02 ----

# directories 
# library(dtplyr)
library(dplyr)
# library(data.table)
library(vroom)
library(parallel)
# library(tictoc)
library(geoR)
library(raster)
library(here)
library(RColorBrewer)

select <- dplyr::select

yannick_dir <- "/rd/gem/private/users/yannickr"
original_effort_dir <- "/rd/gem/private/users/yannickr/effort_mapped_bycountry"
aggregated_files_dir <- "/rd/gem/private/users/yannickr/effort_mapped_by_country_aggregated/"

# check and adjust EEZ file 
(EEZ <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv"))) 
#EEZ data is duplicated in places because of disputed claims to cells - just going to take the first country listed
(EEZ_disputes <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv")) %>% filter(DISPUTED==TRUE))
(take_first <- EEZ_disputes[!duplicated(EEZ_disputes[c("Lon", "Lat")]),])
(EEZ_adj <- bind_rows(EEZ %>% 
            filter(DISPUTED == FALSE),
            take_first) %>%
    select(Lat, Lon, A_Code, Admin_Country) %>% 
    dplyr::rename(eez_country_code = A_Code, 
           eez_country_name = Admin_Country) %>% 
    distinct())

united_coords <- EEZ_adj %>% unite("coords", c("Lon", "Lat"), sep = " ")

EEZ_adj <- EEZ_adj[-which(duplicated(united_coords[,"coords"])==TRUE),] %>% as.data.table() # remove duplicated EEZ records
EEZ_adj <- lazy_dt(EEZ_adj)

#check EEZ data - EEZs look ok
EEZ_xyz <- EEZ_adj %>% as_tibble() %>%  dplyr::rename(x=Lon, y= Lat, z=eez_country_code) %>%  select(x,y,z)  
EEZ_raster <- raster::rasterFromXYZ(EEZ_xyz)

# ggplot(data = EEZ_xyz)+
#   geom_tile(aes(x=x, y=y, fill=z)) + 
#   scale_fill_gradientn(colours = RColorBrewer::brewer.pal(n = 9, name = "Spectral"))

# LME data
(LMEs <- fread(file.path(yannick_dir, "LMESeq.csv")))
LMEs <- lazy_dt(LMEs)

#FAO regions data
(FAO_regions <- readRDS(file.path(yannick_dir, "Cells_LatLon_FAO_regions.rds")) %>% 
    dplyr::rename(Lon=x, Lat = y) %>% mutate(fao_area= as.double(fao_area)) %>% as.data.table())
FAO_regions <- lazy_dt(FAO_regions)

# Looking at the CNumber - this appears the be the iso3n code for the country. This is often the name the same as the admin country but is different when the land masses are territories of other countries

#The data have different rows. Want to make sure they line up
nrow(EEZ_adj) #179904
nrow(as_tibble(LMEs)) #259200
nrow(FAO_regions) #229369

#Some LME data are around that have no FAO or EEZ data
(all_spatial_layers <- 
  full_join(x = full_join(x = LMEs %>% select(-Seq), y = FAO_regions, by = c("Lon", "Lat")), 
            y = EEZ_adj %>% select(Lon, Lat, eez_country_code, eez_country_name), by = c("Lon", "Lat")) %>% as_tibble()
)

missing_fao_eez <- 
  all_spatial_layers %>% 
  filter(is.na(fao_area)) %>% #29831 where FAO areas are NA but LME are not
  filter(is.na(eez_country_code)) #29830 where EEZ are NA but LME are not - this does not change depending on order. So there is one cell where the is LME data and EEZ data but not FAO area data

## end paste ----

# add LME and  EEZ to catchHist ---- 

# head(catchHist) 
# head(LMEs)
# head(EEZ_adj)
# 
# # do lat and long on the LME and EEZ file have the same resolution as in catchHist? yes
# # do loat and long cover the globe? not for catchHist
# 
# unique(sort(as.data.table(catchHist)$Lat))
# unique(sort(as.data.table(catchHist)$Lon))
# 
# unique(sort(as.data.table(LMEs)$Lat))
# unique(sort(as.data.table(LMEs)$Lon))
# 
# unique(sort(as.data.table(EEZ_adj)$Lat))
# unique(sort(as.data.table(EEZ_adj)$Lon))

tic()
catch2 <- catch %>%
  select(-Seq) %>% 
  left_join(LMEs, by=c("Lat", "Lon")) %>%
  left_join(EEZ_adj, by=c("Lat", "Lon")) %>%
  # left_join(FAO_regions, by=c("Lat", "Lon")) %>%
  # mutate(catch = rowsum(across(Reported:Discards), na.rm = TRUE)) %>% 

# WARNING: Should we weight by area here??? Same for effort (in script 02) and same for recent catch!!

  group_by(Year,CNumber,FGroup, LME, eez_country_code,eez_country_name,Sector) %>%
  summarise(Reported = sum(Reported, na.rm = TRUE),
            IUU = sum(IUU, na.rm = TRUE),
            Discards = sum(Discards, na.rm = TRUE)) %>% 
            # Area = sum(Area, na.rm = TRUE)) %>% # WARNING - not sure about area here. LME 0 < LME 9 possibly because not all grid cells are considered but only the ones with catch? 
  # mutate(Year = Year) %>% # WARNING - this was from script 02 - not sure about it, see line above on Year
  ungroup() %>% 
  as.data.table() # NOT SURE WHY I DO THIS HERE - no need for speed anymore but for quick data checking?
toc()

# # should we sum catches?
# catch2<-catch2 %>%
#   rowwise(Year,CNumber, FGroup,LME,eez_country_code,eez_country_name,Sector) %>%
#   dplyr::summarise(catch = sum(Reported,IUU)) %>% # dischards not usually accounted for
#   ungroup() # %>%
#   # mutate(Sector = "Industrial")

```

# add catchHist to catch from Reg and format as effort from Yannick  
*WARNING* update the dataset info - catch is now given as both hist and recent .... 

```{r catch}

# # ORIGIN: downloaded from ISIMIP2b folder and provided by either Reg or Yannick for last round of model runs 
# catch<-read_csv("/rd/gem/private/users/yannickr/catch_histsoc_1950_2014.csv") 
# head(catch)
# sort(unique(catch$FGroup)) # WARNING - limited number of FGroup - complete version will be available soon 

# ORIGIN: created through script 02 from original Yannicks country files in Gem48 and re-arranged and trimmed in script 05.    
effort<-fread("/rd/gem/private/users/yannickr/effort_histsoc_1950_2010.csv")
effort<-effort[,-1]
# sort(unique(effort$FGroup)) 

# head(catch) 
# head(effort) 

# do the LME and EEZ match? ----

# # EEZ - OK
# sort(unique(catch$eez_country_name))
# sort(unique(effort$eez_country_name))
# 
# # LME - OK
# sort(unique(catch$LME)) 
# sort(unique(effort$LME))

# not needed any more as per new data
# # aggregate catch by LME and EEZ, excluding FAO as not in effort and catchHist (but could be added: for effort you would need to change 05_trimFinalData and for catchHist you would need to change the above section) 
# 
# # rename columns before merging and exclude some 
# catch<-catch %>% 
#   mutate(catch = rowSums(across(Reported:IUUs), na.rm = TRUE)) %>% # WARNING - command not working on other files
#   group_by(EEZ, LMEnbr, FGroup, Year, Fcountry, Sector) %>% 
#   summarise(catch = sum(catch, na.rm = TRUE)) %>% # possible to sum AreaSqKm2 assuming that this includes all cell in EEZ and LME?    
#   ungroup() %>% 
#   dplyr::rename(LME = LMEnbr, eez_country_name = EEZ)
# 
# # still discrepancies? Yes, fishing country (SAUP) and fishing group (FGroup) ----
# head(catchHist)
# head(catch) 
# head(effort)  

# fishing country 
saup<-read_csv("/rd/gem/private/users/yannickr/SAUPcode_to_Country.csv")
# head(saup)

# # is CNumber == SAUP? it looks like it BUT hard to say ... 
# sort(unique(catch$CNumber)) 
# sort(unique(saup$SAUP_Country_Nbr))
# unique(filter(catch, CNumber == 124)$eez_country_name)
# filter(saup, SAUP_Country_Nbr == 124)

saup<-saup %>% 
  dplyr::rename(SAUP = SAUP_Country_Nbr,
                FCountryName = Country) %>% 
  select(-Region)

catch2<-catch2 %>% 
  dplyr::rename(SAUP = CNumber) %>% 
  left_join(saup, by ="SAUP")

# head(catch2)

# not needed anymore .... 
# # WARNING - need to check this
# sort(unique(catch$Fcountry))
# sort(unique(saup$ISO3))
# unique(filter(catch, Fcountry == "AGO"))
# unique(filter(catch, Fcountry == "AGO")$eez_country_name)
# filter(saup, ISO3 == "AGO") # is it OK for Angola to fish in all these places? not sure how to check ...  
# 
# catch<-catch %>% 
#   dplyr::rename(ISO3 = Fcountry) %>% 
#   left_join(saup, by = "ISO3") %>% 
#   select(-ISO3, -FCountryName)

# FGroup
# taxon<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/Taxongroups.csv")
taxon<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/CodesRevisedJune2022_FGroup.csv")

# # not matching - updated cacth file will be available soon
# sort(unique(taxon$Description))
# sort(unique(catch$FGroup))  
# sort(unique(effort$FGroup)) 
# 
# # add FGroup to catchHist which now only includes a number code 
# # matching - OK
# sort(unique(taxon$FunctionalGrp)) # missing numbers - are these codes relative to catchHist only? 
# sort(unique(catch$FGroup))
# length(sort(unique(effort$FGroup))) 

# clean
taxon<-taxon %>% 
  mutate(Description = gsub(" ", "", Description, fixed = TRUE),
         Description = gsub(",", "", Description, fixed = TRUE)) %>% # remove white spaces 
  select(FunctionalGrp, Description) %>% 
  unique()

# # any missing one in effort/ catch? No - all OK 
# setdiff(unique(taxon$Description), unique(effort$FGroup))
# setdiff(unique(effort$FGroup),unique(taxon$Description))
# 
# sort(unique(taxon$Description))
# sort(unique(effort$FGroup))

# merge 
catch2<-catch2 %>% 
  # dplyr::rename(TargetGrpNum = FGroup) %>% 
  left_join(taxon %>% dplyr::rename(FGroup = FunctionalGrp)) %>% 
  select(-FGroup) %>% 
  dplyr::rename(FGroup = Description)

### it would be nice to standardise them fully: 
# add LME name and rename LME to LMEnrb
# for effort add FCountryName and/or ISO3 
# also eez col names should be standardised ... 

# sector ... needs to be Industriala dn Artisanal 
catch2<-catch2 %>% 
  mutate(Sector = ifelse(Sector == 2, "artisanal", "industrial"))

# # should we sum catches?
# catch3<-catch2 %>%
#   # as.data.table() %>% # rowwise does not work otherwise but this needs to be checked!!! 
#   rowwise(Year,CNumber, FGroup,LME,eez_country_code,eez_country_name,Sector) %>%
#   dplyr::summarise(catch = sum(Reported,IUU)) %>% # dischards not usually accounted for
#   ungroup() # %>%
#   # mutate(Sector = "Industrial")

```

# check cacth data given Reg summaries and plot

```{r}

annual<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/CheckCatchTotalsCN.csv")

# unique(annual$Sector)
annual<-annual %>% 
  mutate(Sector = ifelse(Sector == "artisanal", "artisanal", "industrial")) %>% 
  select(-"...6") %>% 
  mutate(type = "summaries")

trial<-catch2 %>% 
  group_by(Year, Sector) %>% 
  summarise(Reported = sum(Reported , na.rm = TRUE),
            IUU = sum(IUU , na.rm = TRUE),
            Discards = sum(Discards , na.rm = TRUE)) %>% 
  mutate(type = "dataset")

trial2<-trial %>% 
  full_join(annual) %>% 
  as.data.frame(trial2)

trial2<-trial2 %>% 
  gather("key", "catch", -Year, -type, -Sector)

head(trial2)

ggplot(trial2, aes(x = Year, y = catch, group = key, color = key)) + # color = Sector, group = Sector 
  geom_point()+
  theme_bw()+
  facet_grid(type~Sector)

```

# save final data 

```{r}

# # WARNING - for our analysis now: should we consider only the 6 main groups?
# toKeep <- sort(unique(catch$FGroup))
# final_effort<- effort %>% filter(FGroup %in% toKeep)
final_catch <- catch2
# final_catch_hist <- catchHist %>% filter(FGroup %in% toKeep) 
# final_effort<- effort 

# WARNING - neeed to remove the non-updated version created with previous data from the server after having checked that this is OK 
# save as RData and load to 06_extrapolation_forSpin up - CONSIDER MERGING THE 2 FILES  
save(final_catch, file = "/rd/gem/private/users/yannickr/temp_data_from_FishingEffort_Rpj_07script_update.RData")

```

# explore the Unknown_EEZ FGroup in effort

```{r }

# some FGroup == "Unknown_EEZ", what does this mean? 

a<-filter(effort, FGroup == "Unknown_EEZ")
unique(a$Sector) 
unique(a$SAUP)
unique(a$NomActive)
a<-filter(effort, FGroup == "Unknown_EEZ", SAUP == 892)
unique(a$NomActive)
a<-filter(a, NomActive == 28.926300)
a

# is this group on the original files too?  
this_source_path <- file.path("/rd/gem/private/users/yannickr/effort_mapped_bycountry", "mapped_1992_UP_892.csv")
these_data <- read_csv(this_source_path)

filter(these_data, NomActive ==0) # WARNING I don't understand these 0s... 

b<-filter(these_data, FGroup == "Unknown_EEZ", NomActive !=0)
b 
sum(b$NomActive) 
sum(filter(effort, FGroup == "Unknown_EEZ", SAUP == 892, Year ==1992, NomActive !=0)$NomActive) # OK this is matching... 

```

