---
title: "Catch_data"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

the aim of this file is to aggregate Reg's historical catch data as per Yannick's effort data 

# explore files from Reg 

```{r data}

rm(list=ls())
# 
# library(tidyverse)
# 
# catch<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/HistoricalCell.csv")
# head(catch) 
# sort(unique(catch$ID))
# 
# # # where is the lat/lon for each cell? 
# # Historical.csv
# # LMECells.csv
# # HistoricalCell.csv
# # HistoricalIndex.csv
# # Taxongroups.csv
# # TotalTakeHisttsqkm.csv
# 
# index<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/HistoricalIndex.csv")
# head(index)
# 
# length(sort(unique(catch$Cell))) # NOTE these are not all cells in the globe so need to add the missing ones. 
# 
# length(sort(unique(index$ID))) # this includes more ID then the below meaning that some catch was not allocated to cell
# length(sort(unique(catch$ID)))
# 
# a<-setdiff(unique(index$ID), unique(catch$ID)) # in index but not in catch 
# setdiff(unique(catch$ID), unique(index$ID))
# 
# b<-filter(index, ID %in% a) # they are all unknown records from "Germany" "Denmark" "Finland"
# unique(b$CountryName)
# 
# # Data interpretation
# 
# filter(index, ID == 1021650) # ID specific 
# a<-filter(catch, ID == 1021650, Reported !=0 | IUU !=0 | Discards !=0 ) # this allocates the above to cells - the sum is equal to the above 
# a<-a %>% group_by(ID) %>% summarise(r = sum(Reported), i = sum(IUU), d = sum(Discards))
# a
# 
# # merge the 2 datase this shoudl be the gridded file. you should then exclude the unknown records above making sure taht you keep all cells in the globe  
# trial<-catch %>% 
#   full_join(index)
# 
# sort(unique(trial$Cell))
# 
# nrow(trial)
# nrow(catch) # this should be the same 
# 
# index2<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/Historical.csv")
# head(index2)
# index3<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/LMECells.csv") 
# head(index3)
# index4<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/TotalTakeHisttsqkm.csv")  
# head(index4)
# index5<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/Taxongroups.csv") 
# head(index5)

```

# Add LME and EEZ to historical cacth data from Reg

```{r new data}

library(tidyverse)

catchHist<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/HistoricalCami2.csv")
head(catchHist) 
sort(unique(as.data.table(catchHist)$Year))

# use same approach as in 02_merge_effort_spetial_data.Rmd to add LME, EEZ, FAO regions and aggregate data by these groups

### paste code from script 02 ----

# directories 
library(dtplyr)
library(dplyr)
library(data.table)
library(here)
library(vroom)
library(parallel)
library(tictoc)
library(geoR)
library(raster)
library(here)
library(RColorBrewer)

select <- dplyr::select

yannick_dir <- "/rd/gem/private/users/yannickr"
original_effort_dir <- "/rd/gem/private/users/yannickr/effort_mapped_bycountry"
aggregated_files_dir <- "/rd/gem/private/users/yannickr/effort_mapped_by_country_aggregated/"

# check and adjust EEZ file 
(EEZ <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv"))) 
#EEZ data is duplicated in places because of disputed claims to cells - just going to take the first country listed
(EEZ_disputes <- read_csv(file.path(yannick_dir, "Cells_LatLon_EEZ.csv")) %>% filter(DISPUTED==TRUE))
(take_first <- EEZ_disputes[!duplicated(EEZ_disputes[c("Lon", "Lat")]),])
(EEZ_adj <- bind_rows(EEZ %>% 
            filter(DISPUTED == FALSE),
            take_first) %>%
    select(Lat, Lon, A_Code, Admin_Country) %>% 
    dplyr::rename(eez_country_code = A_Code, 
           eez_country_name = Admin_Country) %>% 
    distinct())

united_coords <- EEZ_adj %>% unite("coords", c("Lon", "Lat"), sep = " ")

EEZ_adj <- EEZ_adj[-which(duplicated(united_coords[,"coords"])==TRUE),] %>% as.data.table() # remove duplicated EEZ records
EEZ_adj <- lazy_dt(EEZ_adj)

#check EEZ data - EEZs look ok
EEZ_xyz <- EEZ_adj %>% as_tibble() %>%  dplyr::rename(x=Lon, y= Lat, z=eez_country_code) %>%  select(x,y,z)  
EEZ_raster <- raster::rasterFromXYZ(EEZ_xyz)

# ggplot(data = EEZ_xyz)+
#   geom_tile(aes(x=x, y=y, fill=z)) + 
#   scale_fill_gradientn(colours = RColorBrewer::brewer.pal(n = 9, name = "Spectral"))

# LME data
(LMEs <- fread(file.path(yannick_dir, "LMESeq.csv")))
LMEs <- lazy_dt(LMEs)

#FAO regions data
(FAO_regions <- readRDS(file.path(yannick_dir, "Cells_LatLon_FAO_regions.rds")) %>% 
    dplyr::rename(Lon=x, Lat = y) %>% mutate(fao_area= as.double(fao_area)) %>% as.data.table())
FAO_regions <- lazy_dt(FAO_regions)

# Looking at the CNumber - this appears the be the iso3n code for the country. This is often the name the same as the admin country but is different when the land masses are territories of other countries

#The data have different rows. Want to make sure they line up
nrow(EEZ_adj) #179904
nrow(as_tibble(LMEs)) #259200
nrow(FAO_regions) #229369

#Some LME data are around that have no FAO or EEZ data
(all_spatial_layers <- 
  full_join(x = full_join(x = LMEs %>% select(-Seq), y = FAO_regions, by = c("Lon", "Lat")), 
            y = EEZ_adj %>% select(Lon, Lat, eez_country_code, eez_country_name), by = c("Lon", "Lat")) %>% as_tibble()
)

missing_fao_eez <- 
  all_spatial_layers %>% 
  filter(is.na(fao_area)) %>% #29831 where FAO areas are NA but LME are not
  filter(is.na(eez_country_code)) #29830 where EEZ are NA but LME are not - this does not change depending on order. So there is one cell where the is LME data and EEZ data but not FAO area data

# CN not sure I need these 2 lines...
# Year <- as.numeric(str_extract(this_file_name, pattern =  "([[:digit:]])+"))
# these_data <- fread(this_source_path)
catchHist <- lazy_dt(catchHist)

## end paste ----

# add LME and  EEZ to catchHist ---- 

head(catchHist) 
head(LMEs)
head(EEZ_adj)

# do lat and long on the LME and EEZ file have the same resolution as in catchHist? yes
# do loat and long cover the globe? not for catchHist

unique(sort(as.data.table(catchHist)$Lat))
unique(sort(as.data.table(catchHist)$Lon))

unique(sort(as.data.table(LMEs)$Lat))
unique(sort(as.data.table(LMEs)$Lon))

unique(sort(as.data.table(EEZ_adj)$Lat))
unique(sort(as.data.table(EEZ_adj)$Lon))

catchHist <- catchHist %>%
  select(-Seq) %>% 
  left_join(LMEs, by=c("Lat", "Lon")) %>%
  left_join(EEZ_adj, by=c("Lat", "Lon")) %>%
  # left_join(FAO_regions, by=c("Lat", "Lon")) %>%
  # mutate(catch = rowsum(across(Reported:Discards), na.rm = TRUE)) %>% 
  group_by(Year,CNumber,FGroup, LME, eez_country_code,eez_country_name) %>%
  summarise(Reported = sum(Reported, na.rm = TRUE),
            IUU = sum(IUU, na.rm = TRUE),
            Discards = sum(Discards, na.rm = TRUE)) %>% 
            # Area = sum(Area, na.rm = TRUE)) %>% # WARNING - not sure about area here. LME 0 < LME 9 possibly because not all grid cells are considered but only the ones with catch? 
  # mutate(Year = Year) %>% # WARNING - this was from script 02 - not sure about it, see line above on Year
  ungroup() %>% 
  as.data.table()

head(catchHist)

catchHist<-catchHist %>%
  rowwise(Year,CNumber, FGroup,LME,eez_country_code,eez_country_name) %>% 
  dplyr::summarise(catch = sum(Reported,IUU,Discards)) %>% 
  ungroup() %>% 
  mutate(Sector = "Industrial")

head(catchHist) 
```

# add catchHist to catch from Reg and format as effort from Yannick  

```{r catch}

catch<-read_csv("/rd/gem/private/users/yannickr/catch_histsoc_1950_2014.csv") 
head(catch)
sort(unique(catch$FGroup)) # WARNING - limited number of FGroup - complete version will be available soon 

effort<-read_csv("/rd/gem/private/users/yannickr/effort_histsoc_1950_2010.csv")
effort<-effort[,-1]
sort(unique(effort$FGroup)) 

head(catchHist)  
head(catch) 
head(effort) 

# do the LME and EEZ match? ----

# EEZ - OK
sort(unique(catchHist$eez_country_name))
sort(unique(catch$EEZ))
sort(unique(effort$eez_country_name))

# LME - OK
sort(unique(catchHist$LME))
sort(unique(catch$LMEnbr)) 
sort(unique(effort$LME))

# aggregate catch by LME and EEZ, excluding FAO as not in effort and catchHist (but could be added: for effort you would need to change 05_trimFinalData and for catchHist you would need to change the above section) 

# rename columns before merging and exclude some 
catch<-catch %>% 
  mutate(catch = rowSums(across(Reported:IUUs), na.rm = TRUE)) %>% # WARNING - command not working on other files
  group_by(EEZ, LMEnbr, FGroup, Year, Fcountry, Sector) %>% 
  summarise(catch = sum(catch, na.rm = TRUE)) %>% # possible to sum AreaSqKm2 assuming that this includes all cell in EEZ and LME?    
  ungroup() %>% 
  dplyr::rename(LME = LMEnbr, eez_country_name = EEZ)

# still discrepancies? Yes, fishing country (SAUP) and fishing group (FGroup) ----
head(catchHist)
head(catch) 
head(effort)  

# fishing country 
saup<-read_csv("/rd/gem/private/users/yannickr/SAUPcode_to_Country.csv")
head(saup)

# is CNumber == SAUP? it looks like it
sort(unique(catchHist$CNumber)) 
sort(unique(saup$SAUP_Country_Nbr))
unique(filter(catchHist, CNumber == 124)$eez_country_name)
filter(saup, SAUP_Country_Nbr == 124)

saup<-saup %>% 
  dplyr::rename(SAUP = SAUP_Country_Nbr,
                FCountryName = Country) %>% 
  select(-Region)

catchHist<-catchHist %>% 
  dplyr::rename(SAUP = CNumber) %>%
  select(-eez_country_code)

# WARNING - need to check this
sort(unique(catch$Fcountry))
sort(unique(saup$ISO3))
unique(filter(catch, Fcountry == "AGO"))
unique(filter(catch, Fcountry == "AGO")$eez_country_name)
filter(saup, ISO3 == "AGO") # is it OK for Angola to fish in all these places? not sure how to check ...  

catch<-catch %>% 
  dplyr::rename(ISO3 = Fcountry) %>% 
  left_join(saup, by = "ISO3") %>% 
  select(-ISO3, -FCountryName)

# FGroup
taxon<-read_csv("/rd/gem/private/users/yannickr/Reg_catchData/Taxongroups.csv")

# not matching - updated cacth file will be available soon
sort(unique(taxon$Descript))
sort(unique(catch$FGroup))  
sort(unique(effort$FGroup)) 

# add FGroup to catchHist which now only includes a number code 
# matching - OK
sort(unique(taxon$TargetGrpNum)) # missing numbers - are these codes relative to catchHist only? 
sort(unique(catchHist$FGroup))
length(sort(unique(taxon$TargetGrpNum))) # 22 groups here 

# clean
taxon<-taxon %>% 
  mutate(Descript = gsub(" ", "", Descript, fixed = TRUE)) %>% # remove white spaces 
  select(TargetGrpNum, Descript) %>% 
  unique()

# merge 
catchHist<-catchHist %>% 
  dplyr::rename(TargetGrpNum = FGroup) %>% 
  left_join(taxon %>% dplyr::rename(FGroup = Descript), by = "TargetGrpNum") %>% 
  select(-TargetGrpNum)
  

# WARNING - for our analysis now: should we consider only the 6 main groups?
toKeep <- sort(unique(catch$FGroup))
final_effort<- effort %>% filter(FGroup %in% toKeep)
final_catch <- catch
final_catch_hist <- catchHist %>% filter(FGroup %in% toKeep) 

# save as RData and load to 06_extrapolation_forSpin up - CONSIDER MERGING THE 2 FILES  
save(final_effort, final_catch, final_catch_hist, file = "/rd/gem/private/users/yannickr/temp_data_from_FishingEffort_Rpj_07script.RData")
```

# explore the Unknown_EEZ FGroup in effort

```{r }

# some FGroup == "Unknown_EEZ", what does this mean? 

a<-filter(effort, FGroup == "Unknown_EEZ")
unique(a$Sector) 
unique(a$SAUP)
unique(a$NomActive)
a<-filter(effort, FGroup == "Unknown_EEZ", SAUP == 892)
unique(a$NomActive)
a<-filter(a, NomActive == 28.926300)
a

# is this group on the original files too?  
this_source_path <- file.path("/rd/gem/private/users/yannickr/effort_mapped_bycountry", "mapped_1992_UP_892.csv")
these_data <- read_csv(this_source_path)

filter(these_data, NomActive ==0) # WARNING I don't understand these 0s... 

b<-filter(these_data, FGroup == "Unknown_EEZ", NomActive !=0)
b 
sum(b$NomActive) 
sum(filter(effort, FGroup == "Unknown_EEZ", SAUP == 892, Year ==1992, NomActive !=0)$NomActive) # OK this is matching... 

```

